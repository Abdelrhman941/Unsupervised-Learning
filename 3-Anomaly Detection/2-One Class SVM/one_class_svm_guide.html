<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>One-Class SVM Algorithm Guide</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            line-height: 1.6;
            color: #333;
            background: linear-gradient(135deg, #f5f7fa 0%, #c3cfe2 100%);
            min-height: 100vh;
            padding: 20px;
        }
        
        .container {
            max-width: 1200px;
            margin: 0 auto;
            background: white;
            border-radius: 15px;
            box-shadow: 0 10px 30px rgba(0,0,0,0.1);
            overflow: hidden;
        }
        
        .header {
            background: linear-gradient(135deg, #ff7e5f 0%, #feb47b 100%);
            color: white;
            padding: 40px;
            text-align: center;
        }
        
        .header h1 {
            font-size: 2.5em;
            margin-bottom: 10px;
            font-weight: 700;
        }
        
        .header p {
            font-size: 1.2em;
            opacity: 0.9;
        }
        
        .content {
            padding: 40px;
        }
        
        .section {
            margin-bottom: 40px;
        }
        
        .section h2 {
            color: #2c3e50;
            font-size: 1.8em;
            margin-bottom: 20px;
            padding-bottom: 10px;
            border-bottom: 3px solid #ff7e5f;
            display: flex;
            align-items: center;
            gap: 10px;
        }
        
        .section h3 {
            color: #34495e;
            font-size: 1.4em;
            margin: 25px 0 15px 0;
        }
        
        .highlight-box {
            padding: 20px;
            border-radius: 10px;
            margin: 20px 0;
            border-left: 5px solid;
        }
        
        .concept-box {
            background: #e3f2fd;
            border-left-color: #2196f3;
            color: #0d47a1;
        }
        
        .advantages-box {
            background: #e8f5e8;
            border-left-color: #4caf50;
            color: #1b5e20;
        }
        
        .limitations-box {
            background: #fce4ec;
            border-left-color: #e91e63;
            color: #880e4f;
        }
        
        .parameters-box {
            background: #fff8e1;
            border-left-color: #ffc107;
            color: #ff6f00;
        }
        
        .math-box {
            background: linear-gradient(135deg, #ff7e5f, #feb47b);
            color: white;
            text-align: center;
            padding: 20px;
            border-radius: 10px;
            margin: 25px 0;
        }
        
        .math-formula {
            background: #f8f9fa;
            border: 1px solid #dee2e6;
            border-radius: 8px;
            padding: 15px;
            margin: 15px 0;
            font-family: 'Courier New', monospace;
            text-align: center;
            color: #2c3e50;
        }
        
        .two-column {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 20px;
            margin: 20px 0;
        }
        
        .use-case {
            background: #f0f4f8;
            border-radius: 10px;
            padding: 20px;
            margin: 15px 0;
            border-left: 4px solid #ff7e5f;
        }
        
        .best-practices {
            background: #e0f7fa;
            border-left: 4px solid #00bcd4;
            padding: 20px;
            border-radius: 10px;
            margin: 20px 0;
        }
        
        .application-card {
            background: #fff8e1;
            border-radius: 10px;
            padding: 20px;
            margin: 10px 0;
            box-shadow: 0 4px 6px rgba(0,0,0,0.05);
            border-left: 4px solid #ff7e5f;
        }
        
        ul, ol {
            padding-left: 20px;
            margin: 15px 0;
        }
        
        ol li, ul li {
            margin-bottom: 8px;
        }

        .card {
            background: white;
            border-radius: 10px;
            padding: 20px;
            margin: 10px 0;
            box-shadow: 0 4px 6px rgba(0,0,0,0.05);
            transition: transform 0.3s ease;
        }
        
        .card:hover {
            transform: translateY(-5px);
        }

        .gradient-divider {
            height: 5px;
            background: linear-gradient(to right, #ff7e5f, #feb47b);
            margin: 30px 0;
            border-radius: 2px;
        }

        @media (max-width: 768px) {
            .two-column {
                grid-template-columns: 1fr;
            }
            
            .header {
                padding: 30px;
            }
            
            .content {
                padding: 20px;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>üîç One-Class Support Vector Machines (One-Class SVM)</h1>
            <p>Advanced Anomaly Detection with Boundary Learning</p>
        </div>
        
        <div class="content">
            <div class="section">
                <h2>üéØ What is One-Class SVM?</h2>
                <div class="concept-box highlight-box">
                    <p>One-Class SVM is a specialized version of the Support Vector Machine algorithm designed to identify anomalies when training data consists predominantly or exclusively of "normal" instances. It creates a decision boundary around the normal data, separating it from the origin in a high-dimensional feature space.</p>
                    <br>
                    <p>The algorithm works by:</p>
                    <ol>
                        <li>Mapping input data to a high-dimensional feature space using a kernel function</li>
                        <li>Finding a hyperplane that separates most data points from the origin with maximum margin</li>
                        <li>Using this boundary to classify new data points: points inside the boundary are considered normal, while those outside are considered anomalies</li>
                    </ol>
                </div>
            </div>
            
            <div class="gradient-divider"></div>

            <div class="section">
                <h2>üßÆ Mathematical Foundation</h2>
                <div class="math-box">
                    <h3>The Mathematics Behind One-Class SVM</h3>
                </div>
                
                <p>One-Class SVM solves the following optimization problem:</p>
                
                <div class="math-formula">
                    min (1/2)||w||¬≤ + (1/vn)‚àëŒæ·µ¢ - œÅ
                    <br>w,Œæ,œÅ
                </div>
                
                <p>subject to:</p>
                <div class="math-formula">
                    - (w¬∑Œ¶(x·µ¢)) ‚â• œÅ - Œæ·µ¢
                    <br>
                    - Œæ·µ¢ ‚â• 0
                </div>
                
                <p>Where:</p>
                <ul>
                    <li>w is the normal vector to the hyperplane</li>
                    <li>Œ¶ is the feature map to a higher dimensional space</li>
                    <li>v ‚àà (0,1] is a parameter controlling the trade-off between maximizing the distance from the origin and containing most of the data in the region created by the hyperplane</li>
                    <li>Œæ·µ¢ are slack variables</li>
                    <li>œÅ is the offset parameter</li>
                </ul>
                
                <p>The decision function is:</p>
                <div class="math-formula">
                    f(x) = sgn((w¬∑Œ¶(x)) - œÅ)
                </div>
            </div>
            
            <div class="gradient-divider"></div>

            <div class="section">
                <h2>üîß Key Parameters</h2>
                <div class="parameters-box highlight-box">
                    <div class="two-column">
                        <div>
                            <h3>Kernel</h3>
                            <p>Function used to transform data into a higher dimensional space</p>
                            <ul>
                                <li>rbf (Radial Basis Function)</li>
                                <li>linear</li>
                                <li>poly (Polynomial)</li>
                                <li>sigmoid</li>
                            </ul>
                        </div>
                        <div>
                            <h3>nu (ŒΩ)</h3>
                            <p>An upper bound on the fraction of training errors and a lower bound on the fraction of support vectors</p>
                            <ul>
                                <li>Controls the trade-off between maximizing the distance and the number of points allowed to be on the wrong side</li>
                                <li>Typically between 0.01 and 0.1</li>
                            </ul>
                        </div>
                    </div>
                    <br>
                    <div class="two-column">
                        <div>
                            <h3>gamma</h3>
                            <p>Kernel coefficient for 'rbf', 'poly', and 'sigmoid' kernels</p>
                            <ul>
                                <li>Controls the influence radius of training examples</li>
                                <li>Smaller gamma means a larger radius</li>
                            </ul>
                        </div>
                        <div>
                            <h3>degree</h3>
                            <p>Degree of the polynomial kernel (only relevant for poly kernel)</p>
                        </div>
                    </div>
                </div>
            </div>
            
            <div class="gradient-divider"></div>
            
            <div class="section">
                <h2>‚úÖ Advantages of One-Class SVM</h2>
                <div class="advantages-box highlight-box">
                    <ul>
                        <li><strong>Effective with High-Dimensional Data:</strong> Works well even when the data has many features</li>
                        <li><strong>Flexibility with Different Kernels:</strong> Can capture complex decision boundaries using different kernel functions</li>
                        <li><strong>Unsupervised Learning:</strong> Doesn't require labeled anomalies for training</li>
                        <li><strong>Theoretical Foundation:</strong> Based on solid mathematical principles</li>
                        <li><strong>Outlier Resistance:</strong> Less influenced by outliers compared to density-based approaches</li>
                    </ul>
                </div>
            </div>
            
            <div class="gradient-divider"></div>
            
            <div class="section">
                <h2>‚ùå Limitations of One-Class SVM</h2>
                <div class="limitations-box highlight-box">
                    <ul>
                        <li><strong>Parameter Sensitivity:</strong> Performance heavily depends on choosing appropriate kernel and parameters</li>
                        <li><strong>Computational Complexity:</strong> Can be slow and memory-intensive for large datasets</li>
                        <li><strong>Non-probabilistic:</strong> Does not provide probability estimates, only binary decisions</li>
                        <li><strong>Feature Scaling:</strong> Requires careful feature scaling for optimal performance</li>
                        <li><strong>Curse of Dimensionality:</strong> May struggle when there are many irrelevant features</li>
                    </ul>
                </div>
            </div>
            
            <div class="gradient-divider"></div>
            
            <div class="section">
                <h2>üöÄ When to Use One-Class SVM</h2>
                <div class="two-column">
                    <div class="use-case">
                        <h3>Limited Anomaly Examples</h3>
                        <p>When you have plenty of normal examples but few or no anomaly examples</p>
                    </div>
                    <div class="use-case">
                        <h3>High-Dimensional Data</h3>
                        <p>For datasets with many features</p>
                    </div>
                    <div class="use-case">
                        <h3>Non-linear Decision Boundaries</h3>
                        <p>When anomalies cannot be separated by linear boundaries</p>
                    </div>
                    <div class="use-case">
                        <h3>Balanced Performance</h3>
                        <p>When you need good recall without sacrificing precision too much</p>
                    </div>
                    <div class="use-case">
                        <h3>Feature Interaction</h3>
                        <p>When anomalies emerge from complex interactions between features</p>
                    </div>
                </div>
            </div>
            
            <div class="gradient-divider"></div>
            
            <div class="section">
                <h2>üîç Applications</h2>
                <div class="two-column">
                    <div class="application-card">
                        <h3>Intrusion Detection</h3>
                        <p>Identifying unusual network traffic patterns</p>
                    </div>
                    <div class="application-card">
                        <h3>Fraud Detection</h3>
                        <p>Detecting fraudulent financial transactions</p>
                    </div>
                    <div class="application-card">
                        <h3>Medical Diagnosis</h3>
                        <p>Finding unusual patient data that may indicate disease</p>
                    </div>
                    <div class="application-card">
                        <h3>Manufacturing Quality Control</h3>
                        <p>Detecting defective products</p>
                    </div>
                    <div class="application-card">
                        <h3>Image Anomaly Detection</h3>
                        <p>Identifying unusual patterns in images</p>
                    </div>
                    <div class="application-card">
                        <h3>System Health Monitoring</h3>
                        <p>Detecting unusual behavior in machinery or systems</p>
                    </div>
                </div>
            </div>
            
            <div class="gradient-divider"></div>
            
            <div class="section">
                <h2>üí° Best Practices</h2>
                <div class="best-practices">
                    <ol>
                        <li><strong>Data Preprocessing:</strong> Always scale features (e.g., using StandardScaler) before applying One-Class SVM</li>
                        <li><strong>Parameter Tuning:</strong> Use cross-validation to find optimal values for nu and gamma</li>
                        <li><strong>Kernel Selection:</strong> Try different kernels (RBF is often a good starting point)</li>
                        <li><strong>Dimensionality Reduction:</strong> Consider applying PCA or feature selection before One-Class SVM</li>
                        <li><strong>Evaluation:</strong> Use appropriate metrics like precision-recall AUC rather than accuracy</li>
                    </ol>
                </div>
            </div>
        </div>
    </div>
</body>
</html>
